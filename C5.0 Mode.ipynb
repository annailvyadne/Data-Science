{"cells":[{"cell_type":"markdown","metadata":{"id":"Kp4wPlUUHCkS"},"source":["Instructions: By continuing the previous model based on the micro video lecture posted(Refer to DS Chapter 6 CARD and C50 Code review). Construct a C5.0 model using the test data set that utilizes the same target variable, predictor variables, and minimum cases criterion. Visualize the decision tree."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"uZzNrMgoG79U","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1705630911335,"user_tz":-480,"elapsed":24154,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}},"outputId":"aaa8ffaf-5aa4-452b-ddca-45b622258e7a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-55debad2-717d-435a-85b1-5cfaf57132ef\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-55debad2-717d-435a-85b1-5cfaf57132ef\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving adult_ch6_test to adult_ch6_test (1)\n","Saving adult_ch6_training to adult_ch6_training (1)\n"]}],"source":["import os\n","import pandas as pd\n","import graphviz\n","import statsmodels.tools as stattools\n","import numpy as np\n","from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","\n","#Importing files uploaded from google colab to load datasets.\n","from google.colab import files\n","uploaded = files.upload()\n","\n","#Reading the uploaded files into Pandas DataFrame.\n","adult_test = pd.read_csv(\"adult_ch6_test\")\n","adult_tr = pd.read_csv(\"adult_ch6_training\")\n","\n","# save target variable\n","y = adult_test[['Income']]\n","#Extracts the variable income and storing its values to variable y."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"X8gmgGraG766","executionInfo":{"status":"ok","timestamp":1705630914393,"user_tz":-480,"elapsed":299,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# convert categorical variable to dummy variables\n","\n","#Converting the 'adult_test' dataframe's column 'marital status' into numPy array.\n","mar_np = np.array(adult_test['Marital status'])\n","# The 'mar_np' NumPy array is performing a one-hot encoding and creating a DataFrame named 'mar_cat'.\n","mar_cat = pd.get_dummies(mar_np)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"-BKt3lJ6G74m","executionInfo":{"status":"ok","timestamp":1705630915640,"user_tz":-480,"elapsed":4,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# combine the dummy variables back with the\n","\n","# Creating a DataFrame named 'mar_cat'.\n","mar_cat_pd = pd.DataFrame(mar_cat)\n","# Concatenating features into DataFrame 'X'.\n","X = pd.concat((adult_test[['Cap_Gains_Losses']], mar_cat_pd), axis = 1)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"slRJZkgLG72P","executionInfo":{"status":"ok","timestamp":1705630917890,"user_tz":-480,"elapsed":3,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# specify names of combined matrix and the target variable\n","\n","#Giving names to the elements in the merged matrix 'X'\n","X_names = [\"Cap_Gains_Losses\", \"Divorced\", \"Married\", \"Never-married\", \"Separated\", \"Widowed\"]\n","# Giving names to the target variable groups (income classes) in 'y'\n","y_names = [\"<=50K\", \">50K\"]"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"mFYspYDwHPSk","executionInfo":{"status":"ok","timestamp":1705630919833,"user_tz":-480,"elapsed":3,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# train C5.0 model\n","\n","# A C5.0 Decision Tree model is trained using given parameters.\n","# The model is set up with a maximum of 5 leaf nodes in the decision tree.\n","c50_01 = DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=75, max_leaf_nodes=5).fit(X,y)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"tytZ_qWkHPQJ","executionInfo":{"status":"ok","timestamp":1705630921982,"user_tz":-480,"elapsed":3,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# obtain tree structure with labeles\n","\n","# Using the export_graphviz function to generate the decision tree structure with labels\n","# The decision tree's visual information is now contained in the 'data' variable.\n","data = export_graphviz(c50_01, out_file=None, feature_names=X_names, class_names=y_names)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"buBZAiQBHPNj","colab":{"base_uri":"https://localhost:8080/","height":599},"executionInfo":{"status":"ok","timestamp":1705630923737,"user_tz":-480,"elapsed":656,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}},"outputId":"6acb9a31-a563-42bc-ba06-645fe380eaf3"},"outputs":[{"output_type":"execute_result","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"695pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 694.50 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-429 690.5,-429 690.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"363,-425 223,-425 223,-342 363,-342 363,-425\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Married &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"293\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.796</text>\n<text text-anchor=\"middle\" x=\"293\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6155</text>\n<text text-anchor=\"middle\" x=\"293\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4674, 1481]</text>\n<text text-anchor=\"middle\" x=\"293\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &lt;=50K</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"284.5,-306 91.5,-306 91.5,-223 284.5,-223 284.5,-306\"/>\n<text text-anchor=\"middle\" x=\"188\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cap_Gains_Losses &lt;= 0.047</text>\n<text text-anchor=\"middle\" x=\"188\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.335</text>\n<text text-anchor=\"middle\" x=\"188\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3262</text>\n<text text-anchor=\"middle\" x=\"188\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3060, 202]</text>\n<text text-anchor=\"middle\" x=\"188\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &lt;=50K</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M256.57,-341.91C248.35,-332.74 239.54,-322.93 231.07,-313.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"233.65,-311.13 224.36,-306.02 228.44,-315.8 233.65,-311.13\"/>\n<text text-anchor=\"middle\" x=\"223.02\" y=\"-327.28\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node5\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"495.5,-306 302.5,-306 302.5,-223 495.5,-223 495.5,-306\"/>\n<text text-anchor=\"middle\" x=\"399\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cap_Gains_Losses &lt;= 0.051</text>\n<text text-anchor=\"middle\" x=\"399\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.99</text>\n<text text-anchor=\"middle\" x=\"399\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2893</text>\n<text text-anchor=\"middle\" x=\"399\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1614, 1279]</text>\n<text text-anchor=\"middle\" x=\"399\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &lt;=50K</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M329.78,-341.91C338.08,-332.74 346.97,-322.93 355.52,-313.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"358.17,-315.78 362.29,-306.02 352.98,-311.08 358.17,-315.78\"/>\n<text text-anchor=\"middle\" x=\"363.52\" y=\"-327.29\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 5 -->\n<g id=\"node3\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"132,-179.5 0,-179.5 0,-111.5 132,-111.5 132,-179.5\"/>\n<text text-anchor=\"middle\" x=\"66\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.247</text>\n<text text-anchor=\"middle\" x=\"66\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3098</text>\n<text text-anchor=\"middle\" x=\"66\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2971, 127]</text>\n<text text-anchor=\"middle\" x=\"66\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &lt;=50K</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145.67,-222.91C133.48,-211.21 120.18,-198.46 108,-186.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110.22,-184.06 100.58,-179.67 105.38,-189.11 110.22,-184.06\"/>\n</g>\n<!-- 6 -->\n<g id=\"node4\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"261.5,-179.5 150.5,-179.5 150.5,-111.5 261.5,-111.5 261.5,-179.5\"/>\n<text text-anchor=\"middle\" x=\"206\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.995</text>\n<text text-anchor=\"middle\" x=\"206\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 164</text>\n<text text-anchor=\"middle\" x=\"206\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [89, 75]</text>\n<text text-anchor=\"middle\" x=\"206\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &lt;=50K</text>\n</g>\n<!-- 1&#45;&gt;6 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M194.25,-222.91C195.89,-212.2 197.67,-200.62 199.34,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"202.84,-190.08 200.9,-179.67 195.92,-189.02 202.84,-190.08\"/>\n</g>\n<!-- 3 -->\n<g id=\"node6\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"447,-179.5 315,-179.5 315,-111.5 447,-111.5 447,-179.5\"/>\n<text text-anchor=\"middle\" x=\"381\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.954</text>\n<text text-anchor=\"middle\" x=\"381\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2506</text>\n<text text-anchor=\"middle\" x=\"381\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1567, 939]</text>\n<text text-anchor=\"middle\" x=\"381\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &lt;=50K</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge5\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M392.75,-222.91C391.11,-212.2 389.33,-200.62 387.66,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"391.08,-189.02 386.1,-179.67 384.16,-190.08 391.08,-189.02\"/>\n</g>\n<!-- 4 -->\n<g id=\"node7\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"658.5,-187 465.5,-187 465.5,-104 658.5,-104 658.5,-187\"/>\n<text text-anchor=\"middle\" x=\"562\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cap_Gains_Losses &lt;= 0.284</text>\n<text text-anchor=\"middle\" x=\"562\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.534</text>\n<text text-anchor=\"middle\" x=\"562\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 387</text>\n<text text-anchor=\"middle\" x=\"562\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [47, 340]</text>\n<text text-anchor=\"middle\" x=\"562\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &gt;50K</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M455.55,-222.91C468.95,-213.29 483.35,-202.95 497.09,-193.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"499.47,-195.7 505.55,-187.02 495.38,-190.01 499.47,-195.7\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"551.5,-68 440.5,-68 440.5,0 551.5,0 551.5,-68\"/>\n<text text-anchor=\"middle\" x=\"496\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.116</text>\n<text text-anchor=\"middle\" x=\"496\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 193</text>\n<text text-anchor=\"middle\" x=\"496\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 190]</text>\n<text text-anchor=\"middle\" x=\"496\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &gt;50K</text>\n</g>\n<!-- 4&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>4&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M537.42,-103.73C532.15,-94.97 526.56,-85.7 521.26,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"524.23,-75.06 516.07,-68.3 518.24,-78.67 524.23,-75.06\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"686.5,-68 569.5,-68 569.5,0 686.5,0 686.5,-68\"/>\n<text text-anchor=\"middle\" x=\"628\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.772</text>\n<text text-anchor=\"middle\" x=\"628\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 194</text>\n<text text-anchor=\"middle\" x=\"628\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [44, 150]</text>\n<text text-anchor=\"middle\" x=\"628\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = &gt;50K</text>\n</g>\n<!-- 4&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>4&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M586.58,-103.73C591.85,-94.97 597.44,-85.7 602.74,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"605.76,-78.67 607.93,-68.3 599.77,-75.06 605.76,-78.67\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.sources.Source at 0x7de7e5543df0>"]},"metadata":{},"execution_count":33}],"source":["# display the plot\n","\n","# Graphviz is used to show the decision tree plot based on the produced \"data.\"\n","# Graphviz is used to render and show the decision tree plot, which gives the model structure a visual representation.\n","# export_graphviz is used to export a decision tree visualization in a format that can be rendered by external tools, such as Graphviz (Galarnyk, 2020).\n","graphviz.Source(data)"]},{"cell_type":"markdown","metadata":{"id":"0nTTuuY5HXzc"},"source":["Use random forests on the training data set to predict income using marital status and capital gains and losses."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"17fKsjPRG7z2","executionInfo":{"status":"ok","timestamp":1705630926793,"user_tz":-480,"elapsed":4,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# import required packages\n","\n","# RandomForestClassifier is being imported from the sklearn.ensemble module.\n","# NumPy import for manipulating arrays and performing numerical calculations\n","from sklearn.ensemble import RandomForestClassifier\n","import numpy as np"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"e8dJEoNsG7xS","executionInfo":{"status":"ok","timestamp":1705630929179,"user_tz":-480,"elapsed":275,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# save target variable\n","\n","# transferring the 'adult_tr' DataFrame's target value 'Income' to the variable 'y'.\n","# Now that the variable 'y' has the goal variable 'Income' assigned to it, the model is prepared for training using the characteristics in 'X'.\n","y = adult_tr['Income']"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"rCIMcx4UG7uX","executionInfo":{"status":"ok","timestamp":1705630931261,"user_tz":-480,"elapsed":470,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# convert categorical variable to dummy variables\n","\n","# transform a category variable into a fake variable\n","# create a DataFrame called \"mar_cat\" with dummy variables for the \"Marital status\" column in the \"adult_tr\" dataset.\n","# np.array is for numerical and mathematical operations (Willems, 2023).\n","mar_np = np.array(adult_tr['Marital status'])\n","mar_cat = pd.get_dummies(mar_np)\n","\n","# get is used to access a group of rows and columns by labels or a boolean array (Suhani, 2020)."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"75HzrKHzHfrd","executionInfo":{"status":"ok","timestamp":1705630933251,"user_tz":-480,"elapsed":4,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# combine the dummy variables back with the\n","\n","# combining the actual feature (Cap_Gains_Losses) and the dummy variables (mar_cat_pd) into DataFrame 'X'\n","# The original feature 'Cap_Gains_Losses' has now been combined with dummy variables to prepare the DataFrame 'X' for model training or analysis.\n","mar_cat_pd = pd.DataFrame(mar_cat)\n","X = pd.concat((adult_tr[['Cap_Gains_Losses']], mar_cat_pd), axis = 1)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"ivjCYeNVHfo_","executionInfo":{"status":"ok","timestamp":1705630935603,"user_tz":-480,"elapsed":320,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# format for random forest model\n","\n","# Using np.ravel, reshape the target variable \"y\" into a flattened array so that it works with RandomForestClassifier\n","# Now that the target variable 'rfy' has been formatted, it can be used to train a Random Forest model as it is an array.\n","rfy = np.ravel(y)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"c5XajObQHfmi","executionInfo":{"status":"ok","timestamp":1705630937933,"user_tz":-480,"elapsed":1094,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# train random forest model\n","\n","# Training 100 estimators in a Random Forest model using Gini impurity as the splitting criteria\n","# For node splitting, the Random Forest model 'rf01' is set up using 100 estimators and the Gini impurity criteria.\n","rf01 = RandomForestClassifier(n_estimators = 100, criterion=\"gini\").fit(X,rfy)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"rnQ-bk5-Hfjr","executionInfo":{"status":"ok","timestamp":1705630939295,"user_tz":-480,"elapsed":10,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# return predictions\n","\n","# Making predictions on the training set with the Random Forest model 'rf01' that has been trained\n","# The Random Forest model's predictions based on the training set of data are now stored in the variable 'rf_train'.\n","rf_train = rf01.predict(X)"]},{"cell_type":"markdown","metadata":{"id":"0iNGju6YH3UW"},"source":["Use random forests using the test data set that utilizes the same target and predictor variables. Does the test data result match the training data result?"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"UX4lz1DFH6BZ","executionInfo":{"status":"ok","timestamp":1705630941139,"user_tz":-480,"elapsed":5,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# save target variable\n","\n","# Encoding the desired variable 'Income' into the variable 'y' from the testing dataset 'adult_test'\n","# Using the 'Income' column from the testing data, the goal variable 'y' is now allocated and prepared for analysis or forecasting.\n","y = adult_test[['Income']]"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"3Iau_37MH5_W","executionInfo":{"status":"ok","timestamp":1705630943695,"user_tz":-480,"elapsed":5,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# convert categorical variable to dummy variables\n","\n","# Using one-hot encoding, the categorical variable \"Marital status\" from the \"adult_test\" DataFrame is transformed into dummy variables.\n","# In order to simulate the values in the 'Marital status' column of the testing data, a DataFrame named'mar_cat' is constructed.\n","\n","mar_np = np.array(adult_test['Marital status'])\n","mar_cat = pd.get_dummies(mar_np)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"Rfcs-9Q-H581","executionInfo":{"status":"ok","timestamp":1705630944925,"user_tz":-480,"elapsed":3,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# combining the original feature \"Cap_Gains_Losses\" with the dummy variables \"mar_cat_pd\" into DataFrame \"X\" for testing\n","# With the addition of dummy variables, the initial feature 'Cap_Gains_Losses' is now ready for testing on the DataFrame 'X'.\n","mar_cat_pd = pd.DataFrame(mar_cat)\n","X = pd.concat((adult_test[['Cap_Gains_Losses']], mar_cat_pd), axis = 1)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"iXhxXeUIH56M","executionInfo":{"status":"ok","timestamp":1705630946056,"user_tz":-480,"elapsed":3,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# format for random forest model\n","\n","# Reshaping the target variable 'y' into a flattened array using np.ravel for compatibility with RandomForestClassifier in testing\n","# The target variable 'rfy' may now be used to make predictions on the testing data using the Random Forest model that has been trained.\n","rfy = np.ravel(y)\n","\n","#np.ravel is used to flatten a multi-dimensional array into a one-dimensional array (Ebner, 2022)."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"xpWs244dH54B","executionInfo":{"status":"ok","timestamp":1705630948156,"user_tz":-480,"elapsed":472,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# train random forest model\n","\n","# Using Gini impurity as the splitting condition and training a Random Forest model with 100 estimators on the testing data\n","# For predicting the testing data, the Random Forest model 'rf01' is set up using 100 estimators and the Gini impurity criteria.\n","rf01 = RandomForestClassifier(n_estimators = 100, criterion=\"gini\").fit(X,rfy)\n","\n","#RandomForestClassifier operates by constructing a multitude of decision trees during training and outputs the class (Shafi, 2023)."]},{"cell_type":"code","execution_count":46,"metadata":{"id":"4zdsTr1xHfg4","executionInfo":{"status":"ok","timestamp":1705630949655,"user_tz":-480,"elapsed":332,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}}},"outputs":[],"source":["# return predictions\n","\n","#Making predictions on the test data with the Random Forest model 'rf01' that has been trained\n","# The predictions that the Random Forest model produced using the testing data are now stored in the variable 'rf_test'.\n","rf_test = rf01.predict(X)"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"oESLzH59G7rS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705630951472,"user_tz":-480,"elapsed":403,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}},"outputId":"2aa08399-92fb-4a4a-823f-1931a667a07e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<=50K    0.926123\n",">50K     0.073877\n","Name: 0, dtype: float64"]},"metadata":{},"execution_count":47}],"source":["#this should have an output\n","\n","# Displaying the distribution of predicted classes on the training data using value_counts, normalized by the total number of predictions\n","# The output provides the proportion of predicted classes in the training data, offering insights into the model's performance.\n","\n","rf_train = pd.DataFrame(rf_train)\n","rf_train[0].value_counts() / len(rf_train)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"q71F8QLkIJJN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705630952734,"user_tz":-480,"elapsed":5,"user":{"displayName":"Lianne Francheska Deldacan","userId":"14617940862369908494"}},"outputId":"ef50dc54-bda9-41c3-9982-be9a4ef7f02a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<=50K    0.926401\n",">50K     0.073599\n","Name: 0, dtype: float64"]},"metadata":{},"execution_count":48}],"source":["#this should have an output\n","\n","# Using value_counts to display the predicted class distribution on the testing data, normalized by the total number of forecasts\n","# The percentage of predicted classes in the testing data is provided in the output, which sheds light on how well the model performs with untested data.\n","rf_test = pd.DataFrame(rf_test)\n","rf_test[0].value_counts() / len(rf_test)"]},{"cell_type":"markdown","metadata":{"id":"McPp0uveIOBx"},"source":["Based on the output, both models should classify the data as 93% for <=50K and 7% for >=50K"]},{"cell_type":"markdown","source":["**References**\n","\n","Ebner, J. (2022, July 11). Numpy Ravel, Explained. Retrieved from Sharp Sight: https://www.sharpsightlabs.com/blog/numpy-ravel/\n","\n","Galarnyk, M. (2020, April 02). Visualizing Decision Trees with Python (Scikit-learn, Graphviz, Matplotlib). Retrieved from Medium: https://towardsdatascience.com/visualizing-decision-trees-with-python-scikit-learn-graphviz-matplotlib-1c50b4aa68dc\n","\n","Shafi, A. (2023, February 06). Random Forest Classification with Scikit-Learn. Retrieved from DataCamp: https://www.datacamp.com/tutorial/random-forests-classifier-python\n","\n","Shuhani, S. (2020, October 08). How to Access a Column in a DataFrame (using Pandas). Retrieved from ActiveState: https://www.activestate.com/resources/quick-reads/how-to-access-a-column-in-a-dataframe-using-pandas/\n","\n","Willems, K. (2023, February 15). Python Numpy Array Tutorial. Retrieved from DataCamp: https://www.datacamp.com/tutorial/python-numpy-tutorial\n","\n"],"metadata":{"id":"Y85BS9bXhaub"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}